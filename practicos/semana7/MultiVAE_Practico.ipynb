{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "MultiVAE_Practico.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ahq3V1FYhx"
      },
      "source": [
        "# Variational autoencoders for collaborative filtering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpghG7ADFYhy"
      },
      "source": [
        "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
        "\n",
        "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzM2Du1O1ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f29ca5-8ba7-4e4b-cced-fd218b619277"
      },
      "source": [
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/6d/2348df00a34baaabdef0fdb4f46f962f7a8a6720362c26c3a44a249767ea/tensorflow_gpu-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.16.4)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.7.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.2MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.1.7)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.0.post1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow-gpu==1.14) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (44.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.1)\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9EU9SzAI1Vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceeb8e01-985b-434e-8b87-2778b48b45e9"
      },
      "source": [
        "!pip install Bottleneck"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Bottleneck\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/08/278c6ee569458e168096f6b51019cc1c81c288da3d1026a22ee2ccead102/Bottleneck-1.3.2.tar.gz (88kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.8MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from Bottleneck) (1.16.4)\n",
            "Building wheels for collected packages: Bottleneck\n",
            "  Building wheel for Bottleneck (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Bottleneck: filename=Bottleneck-1.3.2-cp27-cp27mu-linux_x86_64.whl size=315077 sha256=e4654114d0a75617c29eaeb5d30aa94ed0809f1a5a893ae0c6c6e3cbcff28e5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/a9/12/41b13e8b44889ab05ec4dcc91f27da21634bacf2a0e87473b8\n",
            "Successfully built Bottleneck\n",
            "Installing collected packages: Bottleneck\n",
            "Successfully installed Bottleneck-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK_96uetFYhz"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
        "\n",
        "import bottleneck as bn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8jolZYFYh4"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5WFiDZRFYh5"
      },
      "source": [
        "We load the data and create train/validation/test splits following strong generalization: \n",
        "\n",
        "- We split all users into training/validation/test sets. \n",
        "\n",
        "- We train models using the entire click history of the training users. \n",
        "\n",
        "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmGA2EPQFYh6"
      },
      "source": [
        "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA4ezX8MJUA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85633ae3-57a6-4132-e1b4-f9aa65ec346f"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
        "!unzip /content/ml-20m.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-06 01:14:00--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 198702078 (189M) [application/zip]\n",
            "Saving to: ‘ml-20m.zip’\n",
            "\n",
            "ml-20m.zip          100%[===================>] 189.50M   118MB/s    in 1.6s    \n",
            "\n",
            "2021-10-06 01:14:02 (118 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
            "\n",
            "Archive:  /content/ml-20m.zip\n",
            "   creating: ml-20m/\n",
            "  inflating: ml-20m/genome-scores.csv  \n",
            "  inflating: ml-20m/genome-tags.csv  \n",
            "  inflating: ml-20m/links.csv        \n",
            "  inflating: ml-20m/movies.csv       \n",
            "  inflating: ml-20m/ratings.csv      \n",
            "  inflating: ml-20m/README.txt       \n",
            "  inflating: ml-20m/tags.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-80sYNYFYh7"
      },
      "source": [
        "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
        "DATA_DIR = '/content/ml-20m'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnwdl8CbFYiA"
      },
      "source": [
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn_jtYGHFYiE"
      },
      "source": [
        "# binarize the data (only keep ratings >= 4)\n",
        "raw_data = raw_data[raw_data['rating'] > 3.5]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehnKTGiFYiJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b0ddf6fb-f013-444c-d984-ff85825de64c"
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  movieId  rating   timestamp\n",
              "6        1      151     4.0  1094785734\n",
              "7        1      223     4.0  1112485573\n",
              "8        1      253     4.0  1112484940\n",
              "9        1      260     4.0  1112484826\n",
              "10       1      293     4.0  1112484703"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1094785734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>223</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112485573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>253</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>260</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzYgRQIiFYiO"
      },
      "source": [
        "### Data splitting procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qVs5EEqFYiP"
      },
      "source": [
        "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
        "- Use all the items from the training users as item set\n",
        "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDPvNl-QFYiQ"
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKYy5rGjFYiU"
      },
      "source": [
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWYHa34vFYiX"
      },
      "source": [
        "Only keep items that are clicked on by at least 5 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ytmY4lFYiX"
      },
      "source": [
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay8PGVQDFYia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6d8332-5136-4181-fcc1-b899eec505e2"
      },
      "source": [
        "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After filtering, there are 9990682 watching events from 136677 users and 20720 movies (sparsity: 0.353%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vientq_DFYic"
      },
      "source": [
        "unique_uid = user_activity.index\n",
        "\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDe3B_KYFYif"
      },
      "source": [
        "# create train/validation/test users\n",
        "n_users = unique_uid.size\n",
        "n_heldout_users = 10000\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "te_users = unique_uid[(n_users - n_heldout_users):]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60FBs88zFYih"
      },
      "source": [
        "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxCxoAh1FYik"
      },
      "source": [
        "unique_sid = pd.unique(train_plays['movieId'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCcfXDUvFYin"
      },
      "source": [
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKgIGJy1FYiq"
      },
      "source": [
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fG-zwHSFYis"
      },
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1k2d_g2FYiu"
      },
      "source": [
        "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJU3Ncf7FYiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005b6829-060a-491a-d230-b39e43ffffd5"
      },
      "source": [
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptvFIhlsFYiy"
      },
      "source": [
        "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX261EFPFYi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f95df1-be81-416f-b5ec-7e82f143c9ac"
      },
      "source": [
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfPenbm2FYi3"
      },
      "source": [
        "### Save the data into (user_index, item_index) format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfJU_gBkFYi3"
      },
      "source": [
        "def numerize(tp):\n",
        "    uid = map(lambda x: profile2id[x], tp['userId'])\n",
        "    sid = map(lambda x: show2id[x], tp['movieId'])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUTKUFEAFYi6"
      },
      "source": [
        "train_data = numerize(train_plays)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArJf0e8FYi8"
      },
      "source": [
        "vad_data_tr = numerize(vad_plays_tr)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugbb4-ThFYi_"
      },
      "source": [
        "vad_data_te = numerize(vad_plays_te)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_17Rkt3jFYjB"
      },
      "source": [
        "test_data_tr = numerize(test_plays_tr)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iG-vxzWFYjD"
      },
      "source": [
        "test_data_te = numerize(test_plays_te)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBJhcqMbFYjF"
      },
      "source": [
        "## Model definition and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlEMlH6TFYjF"
      },
      "source": [
        "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNtUyqeFYjF"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcrNQ2mYFYjG"
      },
      "source": [
        "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI37y0ciFYjG"
      },
      "source": [
        "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
        "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCD6bKYFYjH"
      },
      "source": [
        "The objective for Multi-DAE for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
        "$$\n",
        "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNHkjNS_FYjH"
      },
      "source": [
        "class MultiDAE(object):\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        \n",
        "        self.lam = lam\n",
        "        self.lr = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):        \n",
        "        self.input_ph = tf.placeholder(\n",
        "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        # per-user average negative log-likelihood\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph, axis=1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        loss = neg_ll + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('loss', loss)\n",
        "        merged = tf.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # construct forward graph        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return tf.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # define weights\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
        "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_{}\".format(i+1)\n",
        "            \n",
        "            self.weights.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases[-1])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYKe5hIIFYjK"
      },
      "source": [
        "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
        "$$\n",
        "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxGbnGCNFYjK"
      },
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        super(MultiVAE, self).construct_placeholders()\n",
        "\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
        "        \n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph,\n",
        "            axis=-1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        \n",
        "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('KL', KL)\n",
        "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.summary.merge_all()\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "    \n",
        "    def q_graph(self):\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_q) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "            else:\n",
        "                mu_q = h[:, :self.q_dims[-1]]\n",
        "                logvar_q = h[:, self.q_dims[-1]:]\n",
        "\n",
        "                std_q = tf.exp(0.5 * logvar_q)\n",
        "                KL = tf.reduce_mean(tf.reduce_sum(\n",
        "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
        "        return mu_q, std_q, KL\n",
        "\n",
        "    def p_graph(self, z):\n",
        "        h = z\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_p) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # q-network\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        epsilon = tf.random_normal(tf.shape(std_q))\n",
        "\n",
        "        sampled_z = mu_q + self.is_training_ph *\\\n",
        "            epsilon * std_q\n",
        "\n",
        "        # p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        \n",
        "        return tf.train.Saver(), logits, KL\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        self.weights_q, self.biases_q = [], []\n",
        "        \n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1]) - 1:\n",
        "                # we need two sets of parameters for mean and variance,\n",
        "                # respectively\n",
        "                d_out *= 2\n",
        "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_q_{}\".format(i+1)\n",
        "            \n",
        "            self.weights_q.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_q.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
        "            \n",
        "        self.weights_p, self.biases_p = [], []\n",
        "\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
        "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_p_{}\".format(i+1)\n",
        "            self.weights_p.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_p.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_p[-1])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODsCIU-fFYjM"
      },
      "source": [
        "### Training/validation data, hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGSGE8zeFYjM"
      },
      "source": [
        "Load the pre-processed training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEfmgezwFYjM"
      },
      "source": [
        "unique_sid = list()\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhV3WVq4FYjO"
      },
      "source": [
        "def load_train_data(csv_file):\n",
        "    tp = pd.read_csv(csv_file)\n",
        "    n_users = tp['uid'].max() + 1\n",
        "\n",
        "    rows, cols = tp['uid'], tp['sid']\n",
        "    data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                             (rows, cols)), dtype='float64',\n",
        "                             shape=(n_users, n_items))\n",
        "    return data"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmA2gNL3FYjQ"
      },
      "source": [
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1AhXPsNFYjR"
      },
      "source": [
        "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
        "    tp_tr = pd.read_csv(csv_file_tr)\n",
        "    tp_te = pd.read_csv(csv_file_te)\n",
        "\n",
        "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    return data_tr, data_te"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di1oeGm2FYjT"
      },
      "source": [
        "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
        "                                           os.path.join(pro_dir, 'validation_te.csv'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk8iKyDzFYjV"
      },
      "source": [
        "Set up training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETG2JNpGFYjW"
      },
      "source": [
        "N = train_data.shape[0]\n",
        "idxlist = range(N)\n",
        "\n",
        "# training batch size\n",
        "batch_size = 1000\n",
        "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
        "\n",
        "N_vad = vad_data_tr.shape[0]\n",
        "idxlist_vad = range(N_vad)\n",
        "\n",
        "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
        "batch_size_vad = 2000\n",
        "\n",
        "# the total number of gradient updates for annealing\n",
        "total_anneal_steps = 200000\n",
        "# largest annealing parameter\n",
        "anneal_cap = 0.2"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9hAllGaFYjZ"
      },
      "source": [
        "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsRjxtjSFYjZ"
      },
      "source": [
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQz5SmxzFYjb"
      },
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3eDxiwkFYjd"
      },
      "source": [
        "### Train a Multi-VAE^{PR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XTyfWXXFYje"
      },
      "source": [
        "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxge_UC5FYje"
      },
      "source": [
        "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVZTnXauFYje"
      },
      "source": [
        "p_dims = [200, 600, n_items]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUwFoLhRFYjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21df08c-da06-4447-c5ad-eecb19b0e6f3"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1006 01:23:02.971575 140667651278720 deprecation.py:506] From <ipython-input-31-318b0755b4c1>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W1006 01:23:03.212037 140667651278720 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1205: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yd73_vSFYjj"
      },
      "source": [
        "Set up logging and checkpoint directory\n",
        "\n",
        "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
        "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDzGG4VnFYjj"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HRfL9eXFYjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5974ac-da35-4142-eae8-84a0655fe5d3"
      },
      "source": [
        "log_dir = '/content/log/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log directory: /content/log/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onllv_KFFYjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef2441e-84dc-4052-ed0e-3c8c5912ef4f"
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEUws3MBFYjo"
      },
      "source": [
        "n_epochs = 20"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xjH1qvYQ1t_"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ceanmc5-FYjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d67465-e76a-455f-d919-1545c91f896c"
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, \n",
        "                                           global_step=epoch * batches_per_epoch + bnum) \n",
        "            \n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [08:56<00:00, 26.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LemP9VhNFYjt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "bb166efa-d5b3-4631-fa4c-52b30f609e6c"
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeMzPudfFYju"
      },
      "source": [
        "### Load the test data and compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsRAPEkFFYju"
      },
      "source": [
        "test_data_tr, test_data_te = load_tr_te_data(\n",
        "    os.path.join(pro_dir, 'test_tr.csv'),\n",
        "    os.path.join(pro_dir, 'test_te.csv'))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldrY0hJhFYjx"
      },
      "source": [
        "N_test = test_data_tr.shape[0]\n",
        "idxlist_test = range(N_test)\n",
        "\n",
        "batch_size_test = 2000"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKENimMVFYjz"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0)\n",
        "saver, logits_var, _, _, _ = vae.build_graph()    "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZsTJ6wPFYj0"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkeAm-doFYj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c0bac4-3b57-4af4-c6d6-4ad6b8f079c5"
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBd_FOB3FYj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37ffd64-49d9-4b28-a448-36cf7bdb962e"
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "\n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "    \n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W1006 01:32:21.791830 140667651278720 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5jiCJtjFYj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e712e8-98e6-418a-9103-ebebeb3385eb"
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test NDCG@100=0.41004 (0.00208)\n",
            "Test Recall@20=0.38133 (0.00270)\n",
            "Test Recall@50=0.52232 (0.00289)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_UQqKHTbW2Y"
      },
      "source": [
        "## Activity\n",
        "Train and test multi-DAE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt6c7n3vFYj8"
      },
      "source": [
        "### Train a Multi-DAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sxbccfxFYj8"
      },
      "source": [
        "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtERLP50FYj8"
      },
      "source": [
        "p_dims = [200, n_items]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj2JohEIFYj-"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oTDQAmdFYkA"
      },
      "source": [
        "Set up logging and checkpoint directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-47-HpT4FYkA"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ss1ShooFYkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4c0ca0-ae02-4e31-f0b7-f504d7b382be"
      },
      "source": [
        "log_dir = '/content/log/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log directory: /content/log/ml-20m/DAE/I-200-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHnoMeb2FYkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107390f4-d112-4a30-f159-4466adce7f60"
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/DAE/I-200-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXTkHeCwFYkH"
      },
      "source": [
        "n_epochs = 200"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUWc5lnHFYkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701c71f5-8a8c-458a-f968-18daea20fec6"
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "    \n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            feed_dict = {dae.input_ph: X, \n",
        "                         dae.keep_prob_ph: 0.5}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
        "                    \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [1:12:40<00:00, 22.13s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8sTDoZEFYkK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "8d1f248d-6358-4aab-e8ea-47530d28a2b8"
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtAk0mYFYkM"
      },
      "source": [
        "### Compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ8KXJslFYkN"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
        "saver, logits_var, _, _, _ = dae.build_graph()    "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_wplMBeFYkO"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLyop0oFYkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0096cb-b267-4914-b016-477342c437db"
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/DAE/I-200-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jONQoamqFYkQ"
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:    \n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "    \n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "\n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jUmIokmFYkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5152434-5e90-4d7b-b0ce-5579b1cb068d"
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test NDCG@100=0.41877 (0.00212)\n",
            "Test Recall@20=0.38492 (0.00268)\n",
            "Test Recall@50=0.52327 (0.00285)\n"
          ]
        }
      ]
    }
  ]
}